# include statement
include required(classpath("application"))


### System configs
system {
	workflow-restart = true
}

call-caching {
	enabled = true
	invalidate-bad-cache-results = true
}


### Database connection
#
database {
  profile = "slick.jdbc.MySQLProfile$"
  db {
    driver = "com.mysql.jdbc.Driver"
	url = "jdbc:mysql://somrc-mysql-rds.cuovd4ygikd7.us-east-1.rds.amazonaws.com/cromwell?rewriteBatchedStatements=true"
	user = "BLAHBLAHBLAH"
	password = "BLAHBLAHBLAH"
	insert-batch-size = 2000
    connectionTimeout = 50000
  }
}


### SLURM backend

backend {
	default = "SLURM"

	providers {

		SLURM {
			actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"

			config {
				run-in-background = false

				root = "cromwell-workdir"

				filesystems {
					local {
						localization : ["copy", "hard-link", "soft-link"]
						caching {
							duplication-strategy: ["copy", "hard-link", "soft-link"]
							hashing-strategy: "file"
						}
					}					
				}

				runtime-attributes = """
					Int runtime_minutes = 600
					Int cpu = 1
					Int requested_memory_mb = 8000
					String queue = "standard"
					String allocation = "somrc-hpc-workshop"
				"""

				submit = """
					sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} \
						-t ${runtime_minutes} \
						-p ${queue} \
						-A ${allocation} \
						-c ${cpu} \
						--mem=${requested_memory_mb} \
						--wrap "/bin/bash ${script}"
				"""

				job-id-regex = "Submitted batch job (\\d+).*"

				check-alive = "squeue -j ${job_id}"

				kill = "scancel ${job_id}"

			}

		}

	}
}


